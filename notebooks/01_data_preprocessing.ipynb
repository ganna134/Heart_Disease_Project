import pandas as pd

# Define the correct column names from the UCI website
column_names = [
    "age", "sex", "cp", "trestbps", "chol", "fbs", "restecg",
    "thalach", "exang", "oldpeak", "slope", "ca", "thal", "target"
]

# Load the dataset with headers
df = pd.read_csv("heart_disease_cleaned.csv", names=column_names, na_values="?")

# Display first few rows
print(df.head())

# Check for missing values
print(df.isnull().sum())


import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv("heart_disease_cleaned.csv")

# Handle missing values (you can customize this)
df = df.dropna()

# One-hot encode categorical variables (you can specify the exact columns if needed)
df_encoded = pd.get_dummies(df, drop_first=True)

# Scale numerical features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df_encoded)

df_scaled = pd.DataFrame(scaled_features, columns=df_encoded.columns)

# EDA example: Heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df_scaled.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()
